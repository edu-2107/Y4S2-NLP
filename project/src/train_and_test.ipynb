{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7b175eb",
   "metadata": {},
   "source": [
    "# Training and testing phase\n",
    "\n",
    "#### This phase intends to take the pre-processed dataset in a csv file and trains and tests various models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4d24582",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'complaints_preprocessed.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yz/ccjsdp3x4sb_tcmc_jy2f5j00000gn/T/ipykernel_37887/3953711486.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Read the preprocessed dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'complaints_preprocessed.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'complaints_preprocessed.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "# Read the preprocessed dataset\n",
    "df = pd.read_csv('complaints_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf24cde",
   "metadata": {},
   "source": [
    "### First step: Train-test split\n",
    "\n",
    "The first step is to split the dataset into training and testing. Here, we decided on a 80-20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe73b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset (80% training, 20% testing)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['Target'])\n",
    "\n",
    "train_df['narrative'] = train_df['narrative'].fillna(\"\")\n",
    "test_df['narrative'] = test_df['narrative'].fillna(\"\")\n",
    "\n",
    "# Separate features (X) and target labels (y)\n",
    "X_train, y_train = train_df['narrative'], train_df['Target']\n",
    "X_test, y_test = test_df['narrative'], test_df['Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab8de00",
   "metadata": {},
   "source": [
    "### Second step: TF-IDF conversion\n",
    "\n",
    "Here, we chose to use only 10000 words since, otherwise, the models would take too long to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eff0639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to TF-IDF features\n",
    "tfidf = TfidfVectorizer(max_features=10000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cd9461",
   "metadata": {},
   "source": [
    "### Third step: Using the models\n",
    "\n",
    "We used several models to compare results, and although we explored a few more during the semester, the ones we ended up using were:\n",
    "- Logistic Regression\n",
    "- Na√Øve Bayes\n",
    "- Stochastic Gradient Descent\n",
    "- LightGBM\n",
    "- Ridge Classifier\n",
    "- XGBoost\n",
    "- Nearest Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5d84dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Stochastic Gradient Descent\": SGDClassifier(loss='hinge', random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=50),\n",
    "    \"Ridge Classifier\": RidgeClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=50, random_state=42),\n",
    "    \"Nearest Centroid\": NearestCentroid(metric='euclidean')\n",
    "}\n",
    "\n",
    "# Variables to store model results\n",
    "model_names = models.keys()\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b720351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "models[\"Logistic Regression\"].fit(X_train_tfidf, y_train)\n",
    "y_pred = models[\"Logistic Regression\"].predict(X_test_tfidf)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "accuracies.append(acc)\n",
    "f1_scores.append(class_report['weighted avg']['f1-score'])\n",
    "precision_scores.append(class_report['weighted avg']['precision'])\n",
    "recall_scores.append(class_report['weighted avg']['recall'])\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec34b68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "models[\"Naive Bayes\"].fit(X_train_tfidf, y_train)\n",
    "y_pred = models[\"Naive Bayes\"].predict(X_test_tfidf)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "accuracies.append(acc)\n",
    "f1_scores.append(class_report['weighted avg']['f1-score'])\n",
    "precision_scores.append(class_report['weighted avg']['precision'])\n",
    "recall_scores.append(class_report['weighted avg']['recall'])\n",
    "\n",
    "print(\"Naive Bayes\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034bbc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent\n",
    "models[\"Stochastic Gradient Descent\"].fit(X_train_tfidf, y_train)\n",
    "y_pred = models[\"Stochastic Gradient Descent\"].predict(X_test_tfidf)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "accuracies.append(acc)\n",
    "f1_scores.append(class_report['weighted avg']['f1-score'])\n",
    "precision_scores.append(class_report['weighted avg']['precision'])\n",
    "recall_scores.append(class_report['weighted avg']['recall'])\n",
    "\n",
    "print(\"Stochastic Gradient Descent\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76fb707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "models[\"LightGBM\"].fit(X_train_tfidf, y_train)\n",
    "y_pred = models[\"LightGBM\"].predict(X_test_tfidf)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "accuracies.append(acc)\n",
    "f1_scores.append(class_report['weighted avg']['f1-score'])\n",
    "precision_scores.append(class_report['weighted avg']['precision'])\n",
    "recall_scores.append(class_report['weighted avg']['recall'])\n",
    "\n",
    "print(\"LightGBM\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13814be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Classifier\n",
    "models[\"Ridge Classifier\"].fit(X_train_tfidf, y_train)\n",
    "y_pred = models[\"Ridge Classifier\"].predict(X_test_tfidf)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "accuracies.append(acc)\n",
    "f1_scores.append(class_report['weighted avg']['f1-score'])\n",
    "precision_scores.append(class_report['weighted avg']['precision'])\n",
    "recall_scores.append(class_report['weighted avg']['recall'])\n",
    "\n",
    "print(\"Ridge Classifier\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea357f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "models[\"XGBoost\"].fit(X_train_tfidf, y_train)\n",
    "y_pred = models[\"XGBoost\"].predict(X_test_tfidf)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "accuracies.append(acc)\n",
    "f1_scores.append(class_report['weighted avg']['f1-score'])\n",
    "precision_scores.append(class_report['weighted avg']['precision'])\n",
    "recall_scores.append(class_report['weighted avg']['recall'])\n",
    "\n",
    "print(\"XGBoost\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc57f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest Centroid\n",
    "models[\"Nearest Centroid\"].fit(X_train_tfidf, y_train)\n",
    "y_pred = models[\"Nearest Centroid\"].predict(X_test_tfidf)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "accuracies.append(acc)\n",
    "f1_scores.append(class_report['weighted avg']['f1-score'])\n",
    "precision_scores.append(class_report['weighted avg']['precision'])\n",
    "recall_scores.append(class_report['weighted avg']['recall'])\n",
    "\n",
    "print(\"Nearest Centroid\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8dd7a7",
   "metadata": {},
   "source": [
    "### Fourth step: plot the results\n",
    "\n",
    "In this cell, we simply create a plot to compare the accuracies, f1-score, precision and recall of all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b46188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Model Comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bar_width = 0.2\n",
    "x = np.arange(len(model_names))\n",
    "\n",
    "ax.bar(x - 1.5*bar_width, accuracies, bar_width, label='Accuracy', color='skyblue')\n",
    "ax.bar(x - 0.5*bar_width, f1_scores, bar_width, label='F1-Score', color='lightcoral')\n",
    "ax.bar(x + 0.5*bar_width, precision_scores, bar_width, label='Precision', color='lightgreen')\n",
    "ax.bar(x + 1.5*bar_width, recall_scores, bar_width, label='Recall', color='gold')\n",
    "\n",
    "ax.set_xlabel(\"Models\")\n",
    "ax.set_ylabel(\"Scores\")\n",
    "ax.set_title(\"Model Performance Comparison\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names, rotation=30, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
