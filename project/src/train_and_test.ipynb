{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7b175eb",
   "metadata": {},
   "source": [
    "# Training and testing phase\n",
    "\n",
    "#### This phase intends to take the pre-processed dataset in a csv file and trains and tests various models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d24582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "# Read the preprocessed dataset\n",
    "df = pd.read_csv('complaints_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf24cde",
   "metadata": {},
   "source": [
    "### First step: Train-test split\n",
    "\n",
    "The first step is to split the dataset into training and testing. Here, we decided on a 80-20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe73b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset (80% training, 20% testing)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['Target'])\n",
    "\n",
    "train_df['narrative'] = train_df['narrative'].fillna(\"\")\n",
    "test_df['narrative'] = test_df['narrative'].fillna(\"\")\n",
    "\n",
    "# Separate features (X) and target labels (y)\n",
    "X_train, y_train = train_df['narrative'], train_df['Target']\n",
    "X_test, y_test = test_df['narrative'], test_df['Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab8de00",
   "metadata": {},
   "source": [
    "### Second step: TF-IDF conversion\n",
    "\n",
    "Here, we chose to use only 10000 words since, otherwise, the models would take too long to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eff0639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to TF-IDF features\n",
    "tfidf = TfidfVectorizer(max_features=10000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cd9461",
   "metadata": {},
   "source": [
    "### Third step: Using the models\n",
    "\n",
    "We used several models to compare results, and although we explored a few more during the semester, the ones we ended up using were:\n",
    "- Logistic Regression\n",
    "- Na√Øve Bayes\n",
    "- Stochastic Gradient Descent\n",
    "- LightGBM\n",
    "- Ridge Classifier\n",
    "- XGBoost\n",
    "- Nearest Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5d84dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Stochastic Gradient Descent\": SGDClassifier(loss='hinge', random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=50),\n",
    "    \"Ridge Classifier\": RidgeClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=50, random_state=42),\n",
    "    \"Nearest Centroid\": NearestCentroid(metric='euclidean')\n",
    "}\n",
    "\n",
    "# Variables to store model results\n",
    "model_names = models.keys()\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b720351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "models[\"Logistic Regression\"].fit(X_train_tfidf, y_train)\n",
    "y_pred = models[\"Logistic Regression\"].predict(X_test_tfidf)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "accuracies.append(acc)\n",
    "f1_scores.append(class_report['weighted avg']['f1-score'])\n",
    "precision_scores.append(class_report['weighted avg']['precision'])\n",
    "recall_scores.append(class_report['weighted avg']['recall'])\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec34b68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "models[\"Naive Bayes\"].fit(X_train_tfidf, y_train)\n",
    "y_pred = models[\"Naive Bayes\"].predict(X_test_tfidf)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "accuracies.append(acc)\n",
    "f1_scores.append(class_report['weighted avg']['f1-score'])\n",
    "precision_scores.append(class_report['weighted avg']['precision'])\n",
    "recall_scores.append(class_report['weighted avg']['recall'])\n",
    "\n",
    "print(\"Naive Bayes\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034bbc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent\n",
    "models[\"Stochastic Gradient Descent\"].fit(X_train_tfidf, y_train)\n",
    "y_pred = models[\"Stochastic Gradient Descent\"].predict(X_test_tfidf)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "accuracies.append(acc)\n",
    "f1_scores.append(class_report['weighted avg']['f1-score'])\n",
    "precision_scores.append(class_report['weighted avg']['precision'])\n",
    "recall_scores.append(class_report['weighted avg']['recall'])\n",
    "\n",
    "print(\"Stochastic Gradient Descent\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76fb707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "models[\"LightGBM\"].fit(X_train_tfidf, y_train)\n",
    "y_pred = models[\"LightGBM\"].predict(X_test_tfidf)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "accuracies.append(acc)\n",
    "f1_scores.append(class_report['weighted avg']['f1-score'])\n",
    "precision_scores.append(class_report['weighted avg']['precision'])\n",
    "recall_scores.append(class_report['weighted avg']['recall'])\n",
    "\n",
    "print(\"LightGBM\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13814be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Classifier\n",
    "models[\"Ridge Classifier\"].fit(X_train_tfidf, y_train)\n",
    "y_pred = models[\"Ridge Classifier\"].predict(X_test_tfidf)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "accuracies.append(acc)\n",
    "f1_scores.append(class_report['weighted avg']['f1-score'])\n",
    "precision_scores.append(class_report['weighted avg']['precision'])\n",
    "recall_scores.append(class_report['weighted avg']['recall'])\n",
    "\n",
    "print(\"Ridge Classifier\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea357f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "models[\"XGBoost\"].fit(X_train_tfidf, y_train)\n",
    "y_pred = models[\"XGBoost\"].predict(X_test_tfidf)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "accuracies.append(acc)\n",
    "f1_scores.append(class_report['weighted avg']['f1-score'])\n",
    "precision_scores.append(class_report['weighted avg']['precision'])\n",
    "recall_scores.append(class_report['weighted avg']['recall'])\n",
    "\n",
    "print(\"XGBoost\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc57f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest Centroid\n",
    "models[\"Nearest Centroid\"].fit(X_train_tfidf, y_train)\n",
    "y_pred = models[\"Nearest Centroid\"].predict(X_test_tfidf)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "accuracies.append(acc)\n",
    "f1_scores.append(class_report['weighted avg']['f1-score'])\n",
    "precision_scores.append(class_report['weighted avg']['precision'])\n",
    "recall_scores.append(class_report['weighted avg']['recall'])\n",
    "\n",
    "print(\"Nearest Centroid\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8dd7a7",
   "metadata": {},
   "source": [
    "### Fourth step: plot the results\n",
    "\n",
    "In this cell, we simply create a plot to compare the accuracies, f1-score, precision and recall of all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b46188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Model Comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bar_width = 0.2\n",
    "x = np.arange(len(model_names))\n",
    "\n",
    "ax.bar(x - 1.5*bar_width, accuracies, bar_width, label='Accuracy', color='skyblue')\n",
    "ax.bar(x - 0.5*bar_width, f1_scores, bar_width, label='F1-Score', color='lightcoral')\n",
    "ax.bar(x + 0.5*bar_width, precision_scores, bar_width, label='Precision', color='lightgreen')\n",
    "ax.bar(x + 1.5*bar_width, recall_scores, bar_width, label='Recall', color='gold')\n",
    "\n",
    "ax.set_xlabel(\"Models\")\n",
    "ax.set_ylabel(\"Scores\")\n",
    "ax.set_title(\"Model Performance Comparison\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names, rotation=30, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
